---
layout: single
title:  "TIL_11월15일!"
---

'11월 15일 (화)'

## 왜도와 첨도의 정확한 수치까지 알아야 하냐?
> 정확한 수치는 모르더라도 시각화를 해보면 알 수 있다.
> 그런데 변수가 100개 그 이상이라면? 시간이 많이 필요..

요약된 기술통계라 하더라도 자세히 설명하지 못하는 부분들이 존재

그래서 왜도와 첨도는 변수가 수백개 될 때 전체적으로 왜도와 첨도가 높은 값을 추출해서 전처리 할 수 있다!

당뇨병 데이터에 있던 대부분의 0으로 된 데이터가 현실세계에서 생각했을 때 0이 될 수 없는 값입니다. 혈당, 인슐린수치, 혈압 등  여기에서는 화장실 수, 2층면적, 지하면적, 주차장면적 은 해당 시설이 없다면 0이 될 수 있다.  그래서 전처리를 할 때 현실세계에서 해당 값이 0이 될 수 있는지 없는지를 고민해 보고 전처리 하면 된다!  
plt.show()

plt.show()는 그래프를 보여주는 역할을 함

기존 주피터 에서는 그래프를 보여주는게 기본값이 아니었음

그런데 마지막 줄에 그래프를 그리는 코드가 있다면 보여주는 것이 기본 값으로 변경이 됨

그래서 plt.show()를 했을 때 주피터 버전에 따라 중복 출력이 될 수도 있는데 이때는 plt.show()를 지워주면 해결

0702실습 흐름(feat.규호님)

1. 다양한 변수의 타입을 확인해보고 hist를 활용해 카테고리형 변수와 연속형 변수를 구분해줍니다. 

2. 분류해준 연속형 변수를 hist를 통해서 분포를 확인해봅니다. 

3. 왜도와 첨도를 확인하여 분포가 치우쳐진 연속형 변수를 확인합니다. (모델 학습 결과를 더 끌어올리기 위해서 입니다.

4. 분포가 치우쳐진 변수를 확인 후 추출하여 로그 변환을 진행해줍니다. 



범주형 변수에서 결측치가 없는 변수 선택

범주형 변수 중에 결측치가 있는지 확인을 해보고 어떤 범주형 변수를 선택해서 모델에 사용할지 의사결정을 하게 됨

위에서 이미 결측치를 대부분 채워주었기 때문에 결측치가 거의 없지만 여전히 남아있는 결측치도 있다!

정렬을 하고 결측치가 있는 데이터를 제거하기 위해 슬라이싱을 사용

범주형 데이터는 원핫인코딩 작업을 하기 때문에 결측치를 남겨두어도 상관 X

없는 값은 변수로 생성하지 않기 때문


1) 2억=>4억으로 예측하는 집값은, 2) 100억=>110억으로 예측했을 때 어디에 더 패널티를 줄 것인지

MAE => 1) 2억차이, 2)10억, 오차의 절대값

MSE => 1) 4억차이, 2)100억차이, 오차가 크면 클수록 값은 더 벌어집니다.

RMSLE => 1) np.log(2) => 0.69, 2) np.log(10) => 2.30 

=> 로그값은 작은 값에서 더 패널티를 주고 값이 커짐에 따라 완만하게 증가합니다.
=> 로그값이 작은 값에서 더 패널티를 주는 것은 로그 그래프를 떠올려 보세요.


```python
# append 봉지과자를 통쨰로 넣음
a = []
a.append([1, 2, 3])
a
[[1,2,3]]
```

```python
# extend 봉지과자를 뜯어서 낱개로 넣음
a = []
a.extend([1,2,3])
a
[1,2,3]
```

r^2 score = 결정계수

다른 오차 측정 방법은 작을 수록 오차가 적음을 의미하지만
결정계수는 1에 가까운 값일 수록 잘 예측한 값임


캐글에 보면 익명화된 데이터가 많다.

회사 보안상 이슈 문제 등으로 익명화된 데이터를 제공하기도 합니다.

캐글 Benz 데이터 
 
X는 feature, 독립변수, 2차원 array 형태, 학습할 피처, 예) 시험의 문제

y는 label, 종속변수, target, 정답, 1차원 벡터, 예) 시험의 정답

handle_unknown="ignore" test 에는 등장하지만  train에는 없다면 무시하는데 train으로 피처의 기준을 만드는데 test 에 train에 없는 값이 있다면 그 값은 피처로 만들지 않는다.

fit은 train 에만 합니다. test에는 fit하지 않습니다. train을 기준으로 삼기 위해서임!

test 는 fit을 하지 않고 transform만!

OneHotEncoder 는 전체 데이터를 변환하기 때문에 범주가 아닌 수치 데이터도 모두 인코딩 합니다.

그래서 범주값 데이터만 따로 넣어 인코딩해주어야 합니다.

pd.get_dummies() 의 장점은 이런 전처리 없이 범주 데이터만 OneHotEncoding 하는 것이다.

타이타닉 데이터의 embarked 처럼 S, C, Q 정도의 3가지 값만 있는 간단한 변수 몇 가지라면 손으로 인코딩해도 되지만 

여기에서처럼 변수가 많을 때는 OneHotEncoder 나 
pd.get_dummies() 를 사용하는 것이 훨씬 편함!

