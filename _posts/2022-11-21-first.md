---
layout: single
title:  "TIL_11월21일"
---


11월 21일 월요일

선형회귀보다 트리계열 모델을 사용하면 같은 데이터 셋임에도 훨씬 나은 성능을 보여준다.

이상치도 포함되어 있다. 회귀 모델은 이상치에 민감하기도 하고 다른 수치 데이터에 대하여 전처리가 많이 필요하다.

선형회귀는 간단하고 이해하기 쉽다는 장점이 있지만 설명력이 떨어진다는 단점이 있다.

선형 회귀에 맞는 데이터 셋을 사용한다면 좋은 성능을 낼 수 있음!

## 엑스트라 트리 모델(Extra Tree)

주요 파라미터

## n_estimators : 숲에 있는 나무의 수
## criterion : 분할의 품질을 측정하는 기능
## max_depth : 트리의 최대 깊이
## min_samples_split : 내부 노드를 분할하는 데 필요한 최소 샘플 수
## max_features : 최상의 분할을 찾을 때 고려해야 할 기능의 수


특징)
* 분기 지점을 랜덤으로 선택하기 때문에 랜덤 포레스트보다 속도가 더 빠름
* 1과 동일한 이유로 랜덤 포레스트보다 더 많은 특성을 고려할 수 있음
* 랜덤 포레스트와 동일한 원리를 이용하기 때문에 많은 특징을 공유함
* 랜덤포레스트와 비교해 성능이 미세하게 우위에 있음

![WASSlZzNa8L9KYZwcouSlodQFRAfRzpMk7jFOVr1gKaGfEKEoGuJRwqXFaLMcgqHGwUcgRDyPthFg3vERdJ8EcmZVLye5ugTjnmaofeiwZ9UL6fILSGWEKoNfV8-](https://user-images.githubusercontent.com/99530946/203005588-445c332c-3a6d-4e00-ae0a-5b4490fb7825.png)





‘Gradient-Boosting-Regressior’

## GBM

* 회귀 또는 분류 분석을 수행할 수 있는 예측모형이며, 예측모형의 앙상블 방법론 중 부스팅 계열에 속하는 알고리즘


* 머신러닝 알고리즘 중에서도 가장 예측 성능이 높다고 알려진 알고리즘으로 GBM 구현한 패키지들이 다수

* GBM은 계산량이 상당히 많이 필요한 알고리즘이기 때문에, 이를 하드웨어 효율적으로 구현하는 것이 필요


## 특징)

* 랜덤 포레스트와 다르게 무작위성이 없다.
* 매개변수를 잘 조정해야 하고 훈련 시간이 길다.
* 데이터의 스케일에 구애받지 않는다.
* 고차원의 희소한 데이터에 잘 작동하지 않는다.


주요 파라미터)

## loss : 최적화 시킬 손실함수
## learning_rate : 각 트리의 기여도를 제한하는 파라미터
## n_estimators : 부스팅 단계를 지정하는 파라미터
## subsample: 개별 기본 학습자를 맞추는 데 사용할 샘플의 비율












